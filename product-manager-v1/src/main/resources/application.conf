akka {
  #loggers = ["de.heikoseeberger.akkalog4j.Log4jLogger"]
  #logging-filter = "de.heikoseeberger.akkalog4j.Log4jLoggingFilter"

  loggers = ["akka.event.Logging$DefaultLogger", "akka.event.slf4j.Slf4jLogger"]

  #loggers = ["akka.event.slf4j.Slf4jLogger"]
  #logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  #loggers = ["akka.event.jul.JavaLogger"]
  #logging-filter = "akka.event.jul.JavaLoggingFilter"

  logger-startup-timeout = 20s
  log-level = INFO

  actor {
    guardian-supervisor-strategy = "com.stackline.infra.akka.ProducerSupervisorStrategy"
  }

  kafka {
    #bootstrap.servers = "localhost:9092"
    #bootstrap.servers = ${?KAFKA_HOSTS}

    consumer {
      # Tuning property of scheduled polls.
      poll-interval = 100ms

      # Tuning property of the `KafkaConsumerSettings.poll` parameter.
      # Note that non-zero value means that blocking of the thread that
      # is executing the stage will be blocked.
      poll-timeout = 100ms

      # The stage will be await outstanding offset commit requests before
      # shutting down, but if that takes longer than this timeout it will
      # stop forcefully.
      stop-timeout = 30s

      # How long to wait for `KafkaConsumerSettings.close`
      close-timeout = 20s

      # If offset commit requests are not completed within this timeout
      # the returned Future is completed `TimeoutException`.
      commit-timeout = 60s

      # If the KafkaConsumerSettings can't connect to the broker the poll will be
      # aborted after this timeout. The KafkaConsumerActor will throw
      # org.apache.kafka.common.errors.WakeupException which will be ignored
      # until max-wakeups limit gets exceeded.
      wakeup-timeout = 30s

      # After exceeding maxinum wakeups the consumer will stop and the stage will fail.
      max-wakeups = 999

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by the KafkaConsumerActor. Some blocking may occur.
      use-dispatcher = "akka.kafka.default-dispatcher"

      # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
      # can be defined in this configuration section.
      kafka-clients {
        # if there is no previous offset, either start from "earlieset" or "latest"
        auto.offset.reset = "earliest"
        bootstrap.servers = "localhost:9092"
        bootstrap.servers = ${?KAFKA_HOSTS}
        # Disable auto-commit by default
        enable.auto.commit = false
        # fetch max bytes per poll to attempt to (wont throw error if the actual fetch is greater than config)
        #*fetch.max.bytes = 524288
        group.id = "product-manager-v1"
        heartbeat.interval.ms = 20000
        # poll max [n] messages at a time
        #*max.poll.records = 100
        #*max.partition.fetch.bytes = 524288
        # size of TCP buffer
        #*receive.buffer.bytes = 65536
        session.timeout.ms = 60000
      }
    }

    producer {
      parallelism = 100
      close-timeout = 60s
      use-dispatcher = "akka.kafka.default-dispatcher"

      kafka-clients {
        acks = all
        acks = ${?KAFKA_ACKS}
        batch.size = 16384
        bootstrap.servers = "localhost:9092"
        bootstrap.servers = ${?KAFKA_HOSTS}
        buffer.memory = 67108864
        client.id = ${?HOSTNAME}
        client.id = ${?KAFKA_CLIENT_ID}
        compression.type = "snappy"
        linger.ms = 1
        retries = 30
      }
    }
  }
}
